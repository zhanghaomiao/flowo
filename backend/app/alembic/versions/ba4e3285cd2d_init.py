"""init

Revision ID: ba4e3285cd2d
Revises:
Create Date: 2025-06-20 09:27:00.054278

"""

from collections.abc import Sequence

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "ba4e3285cd2d"
down_revision: str | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "workflows",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("snakefile", sa.String(), nullable=True),
        sa.Column("started_at", sa.DateTime(), nullable=False),
        sa.Column("end_time", sa.DateTime(), nullable=True),
        sa.Column(
            "status",
            sa.Enum("RUNNING", "SUCCESS", "ERROR", "WAITING", "UNKNOWN", name="status"),
            nullable=True,
        ),
        sa.Column("command_line", sa.String(), nullable=True),
        sa.Column("dryrun", sa.Boolean(), nullable=False),
        sa.Column("rulegraph_data", sa.JSON(), nullable=True),
        sa.Column("logfile", sa.String(), nullable=True),
        sa.Column("user", sa.String(), nullable=True),
        sa.Column("tags", postgresql.ARRAY(sa.String()), nullable=True),
        sa.Column("name", sa.String(), nullable=True),
        sa.Column("configfiles", postgresql.ARRAY(sa.String()), nullable=True),
        sa.Column("directory", sa.String(), nullable=True),
        sa.Column("config", sa.JSON(), nullable=True),
        sa.Column("flowo_working_path", sa.String(), nullable=True),
        sa.Column("run_info", sa.JSON(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "rules",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("workflow_id", sa.Uuid(), nullable=False),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflows.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "errors",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("timestamp", sa.DateTime(), nullable=False),
        sa.Column("exception", sa.String(), nullable=False),
        sa.Column("location", sa.String(), nullable=True),
        sa.Column("traceback", sa.Text(), nullable=True),
        sa.Column("file", sa.String(), nullable=True),
        sa.Column("line", sa.String(), nullable=True),
        sa.Column("rule_id", sa.Integer(), nullable=True),
        sa.Column("workflow_id", sa.Uuid(), nullable=False),
        sa.ForeignKeyConstraint(
            ["rule_id"],
            ["rules.id"],
        ),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflows.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "jobs",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("snakemake_id", sa.Integer(), nullable=False),
        sa.Column("workflow_id", sa.Uuid(), nullable=False),
        sa.Column("rule_id", sa.Integer(), nullable=True),
        sa.Column("message", sa.String(), nullable=True),
        sa.Column("wildcards", sa.JSON(), nullable=True),
        sa.Column("reason", sa.String(), nullable=True),
        sa.Column("resources", sa.JSON(), nullable=True),
        sa.Column("shellcmd", sa.String(), nullable=True),
        sa.Column("threads", sa.Integer(), nullable=True),
        sa.Column("priority", sa.Integer(), nullable=True),
        sa.Column(
            "status",
            sa.Enum("RUNNING", "SUCCESS", "ERROR", "WAITING", "UNKNOWN", name="status"),
            nullable=False,
        ),
        sa.Column("started_at", sa.DateTime(), nullable=False),
        sa.Column("end_time", sa.DateTime(), nullable=True),
        sa.Column("group_id", sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(
            ["rule_id"],
            ["rules.id"],
        ),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflows.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "files",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("path", sa.String(), nullable=False),
        sa.Column(
            "file_type",
            sa.Enum("INPUT", "OUTPUT", "LOG", "BENCHMARK", name="filetype"),
            nullable=False,
        ),
        sa.Column("job_id", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["job_id"],
            ["jobs.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    # ### end Alembic commands ###

    # Create notification triggers for real-time updates
    op.execute("""
    CREATE OR REPLACE FUNCTION notify_table_changes()
    RETURNS trigger AS $$
    DECLARE
        payload JSONB;
        entity_id TEXT;  
        workflow_id TEXT;
        current_record RECORD;

    BEGIN
        IF (TG_OP = 'DELETE') THEN current_record := OLD; ELSE current_record := NEW; END IF;

        -- 1. 区分 路由ID 和 实体ID
        IF TG_TABLE_NAME = 'workflows' THEN
            entity_id  := current_record.id::TEXT;
            workflow_id := current_record.id::TEXT;
        ELSIF TG_TABLE_NAME = 'jobs' THEN
            entity_id  := current_record.id::TEXT;          -- 自己的 ID
            workflow_id := current_record.workflow_id::TEXT;
        END IF;

        -- 2. 构建 Payload (传 entity_id)
        payload := jsonb_build_object(
            'table', TG_TABLE_NAME,
            'operation', TG_OP,
            'id', entity_id, 
            'workflow_id', workflow_id,
            'timestamp', EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)
        );

        IF TG_OP = 'UPDATE' OR TG_OP = 'INSERT' THEN
            payload := payload || jsonb_build_object('new_status', NEW.status);
        END IF;

        PERFORM pg_notify('global_events', payload::TEXT);
        RETURN NULL;
    END;
    $$ LANGUAGE plpgsql;

    -- Create triggers
    CREATE TRIGGER workflows_notify_trigger
        AFTER INSERT OR UPDATE OR DELETE ON workflows
        FOR EACH ROW EXECUTE FUNCTION notify_table_changes();

    CREATE TRIGGER jobs_notify_trigger
        AFTER INSERT OR UPDATE OR DELETE ON jobs
        FOR EACH ROW EXECUTE FUNCTION notify_table_changes();
    """)


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # Drop triggers and function
    op.execute("""
    DROP TRIGGER IF EXISTS jobs_notify_trigger ON jobs;
    DROP TRIGGER IF EXISTS workflows_notify_trigger ON workflows;
    DROP FUNCTION IF EXISTS notify_table_changes();
    """)

    op.drop_table("files")
    op.drop_table("jobs")
    op.drop_table("errors")
    op.drop_table("rules")
    op.drop_table("workflows")
    # ### end Alembic commands ###
